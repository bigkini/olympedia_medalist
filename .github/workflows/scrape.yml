name: "90-Day Stealth Scraper"

on:
  schedule:
    - cron: '5 * * * *' # 매시간 5분에 실행
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up R
        uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - name: Cache R packages
        uses: actions/cache@v3
        with:
          path: ${{ env.R_LIBS_USER }}
          key: ${{ runner.os }}-r-${{ hashFiles('**/lockfile') }}
          restore-keys: ${{ runner.os }}-r-

      - name: Install dependencies
        run: |
          Rscript -e 'if(!require("tidyverse")) install.packages("tidyverse")'
          Rscript -e 'if(!require("httr")) install.packages("httr")'
          Rscript -e 'if(!require("rvest")) install.packages("rvest")'
          Rscript -e 'if(!require("janitor")) install.packages("janitor")'
          Rscript -e 'if(!require("jsonlite")) install.packages("jsonlite")'

      - name: Run Scraper
        run: Rscript scraper.R

      - name: Push results
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add data/
          git commit -m "Stealth update: $(date)" || echo "No changes"
          git push
